{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41ea549",
   "metadata": {},
   "source": [
    "Date of Implementation: 19/06/2025<br>\n",
    "Date of Submission: 20/06/2025\n",
    "\n",
    "<center><h3>Lab 1: Text Processing and Regular Expression</h3></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1240c2",
   "metadata": {},
   "source": [
    "<h5>Question 1: Installing NLTK, NLTK.book and Practice the NLP Environment using the exercises 1 and 2 from the given link. Language Processing and Python (nltk.org)</h5>\n",
    "<p>Program Description: Installing and downloading NLTK package in python. Using the above give reference we practice how to use the package in pyhton and perform certain operation as mentioned in the document.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: NLTK</li>\n",
    "<li>Using the NLTK library we implement and practices NLP tasks. Different functions are used to check how words in a text are contextually similar to one another. </li>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962b20aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import+ing necessory libraries\n",
    "import nltk\n",
    "from nltk import *\n",
    "from nltk.book import *\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba5ce01e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1\n",
      "\n",
      "<Text: Moby Dick by Herman Melville 1851>\n",
      "['Call', 'me', 'Ishmael', '.']\n",
      "['The', 'family', 'of', 'Dashwood', 'had', 'long', 'been', 'settled', 'in', 'Sussex', '.']\n",
      "\n",
      "Occurance of the word monstorous with some context: \n",
      "Displaying 11 of 11 matches:\n",
      "ong the former , one was of a most monstrous size . ... This came towards us , \n",
      "ON OF THE PSALMS . \" Touching that monstrous bulk of the whale or ork we have r\n",
      "ll over with a heathenish array of monstrous clubs and spears . Some were thick\n",
      "d as you gazed , and wondered what monstrous cannibal and savage could ever hav\n",
      "that has survived the flood ; most monstrous and most mountainous ! That Himmal\n",
      "they might scout at Moby Dick as a monstrous fable , or still worse and more de\n",
      "th of Radney .'\" CHAPTER 55 Of the Monstrous Pictures of Whales . I shall ere l\n",
      "ing Scenes . In connexion with the monstrous pictures of whales , I am strongly\n",
      "ere to enter upon those still more monstrous stories of them which are to be fo\n",
      "ght have been rummaged out of this monstrous cabinet there is no telling . But \n",
      "of Whale - Bones ; for Whales of a monstrous size are oftentimes cast up dead u\n",
      "\n",
      "Words that are in similar range of context: \n",
      "true contemptible christian abundant few part mean careful puzzled\n",
      "mystifying passing curious loving wise doleful gamesome singular\n",
      "delightfully perilous fearless\n",
      "\n",
      "Common contexts shared by two words: \n",
      "am_glad a_pretty a_lucky is_pretty be_glad\n"
     ]
    }
   ],
   "source": [
    "#Question 1\n",
    "print(\"Question 1\\n\")\n",
    "\n",
    "\n",
    "print(text1)\n",
    "\n",
    "\n",
    "print(sent1)\n",
    "\n",
    "print(sent2)\n",
    "\n",
    "\n",
    "print(\"\\nOccurance of the word monstorous with some context: \")\n",
    "text1.concordance(\"monstrous\")\n",
    "\n",
    "\n",
    "print(\"\\nWords that are in similar range of context: \")\n",
    "text1.similar(\"monstrous\")\n",
    "\n",
    "print(\"\\nCommon contexts shared by two words: \")\n",
    "text2.common_contexts([\"monstrous\", \"very\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa66b7f6",
   "metadata": {},
   "source": [
    "<h5>Question 2: Text Processing (Basics)</h5>\n",
    "1. Define a string containing a paragraph as the value.\n",
    "<p>Program Logic:\n",
    "Storing a paragrah into a variable <i>String str_para\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e4149f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "str_para = \"\"\"Formula One (F1) is the highest class of worldwide\n",
    " racing for open-wheel single-seater formula racing cars sanctioned by the Fédération \n",
    " Internationale de l'Automobile (FIA). The FIA Formula One World Championship has been one of the world's \n",
    " premier forms of motorsport since its inaugural running in 1950 and is often considered to be the pinnacle of \n",
    " motorsport. The word formula in the name refers to the set of rules all participant cars must follow. \n",
    " A Formula One season consists of a series of races, known as Grands Prix. Grands Prix take place in multiple \n",
    " countries and continents on either purpose-built circuits or closed roadsz.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667ba4c9",
   "metadata": {},
   "source": [
    "2.Write a program to print the number of total words and total unique words in the paragraph.\n",
    "<p>Program Description: The first step to preprocessing a given text is to find the length of the paragraph or the number of words and charachters in it. Then we find the number of unique words that are available in the paragraph.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Split the paragraph into a list containg the words of the paragraph using <i>.split()</i></li>\n",
    "<li>To find the length use <i>len()</i> </li>\n",
    "<li>To get the unique words we convert the list into a set using <i>set()</i>. A set can have only unique items in them therfore all the repeating words gets cancelled.</li>\n",
    "<li>Use <i>len()</i> function to get the length of the unique words.  </li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56253fa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q2 b\n",
      "['Formula', 'One', '(F1)', 'is', 'the', 'highest', 'class', 'of', 'worldwide', 'racing', 'for', 'open-wheel', 'single-seater', 'formula', 'racing', 'cars', 'sanctioned', 'by', 'the', 'Fédération', 'Internationale', 'de', \"l'Automobile\", '(FIA).', 'The', 'FIA', 'Formula', 'One', 'World', 'Championship', 'has', 'been', 'one', 'of', 'the', \"world's\", 'premier', 'forms', 'of', 'motorsport', 'since', 'its', 'inaugural', 'running', 'in', '1950', 'and', 'is', 'often', 'considered', 'to', 'be', 'the', 'pinnacle', 'of', 'motorsport.', 'The', 'word', 'formula', 'in', 'the', 'name', 'refers', 'to', 'the', 'set', 'of', 'rules', 'all', 'participant', 'cars', 'must', 'follow.', 'A', 'Formula', 'One', 'season', 'consists', 'of', 'a', 'series', 'of', 'races,', 'known', 'as', 'Grands', 'Prix.', 'Grands', 'Prix', 'take', 'place', 'in', 'multiple', 'countries', 'and', 'continents', 'on', 'either', 'purpose-built', 'circuits', 'or', 'closed', 'roadsz.']\n",
      "\n",
      "Length of the paragraph:  103\n",
      "\n",
      "Number of unique words:  78\n",
      "[(' ', 107), ('e', 53), ('o', 48), ('r', 43), ('n', 43), ('s', 40), ('i', 36), ('a', 35), ('t', 34), ('l', 26), ('c', 18), ('u', 16), ('d', 16), ('h', 15), ('m', 14), ('f', 14), ('p', 13), ('F', 7), ('w', 7), ('g', 6)]\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nQ2 b\")\n",
    "str_list = str_para.split()\n",
    "print(str_list)\n",
    "\n",
    "print(\"\\nLength of the paragraph: \", len(str_list))\n",
    "print(\"\\nNumber of unique words: \", len(set(str_list)))\n",
    "\n",
    "\n",
    "Freq_Words = FreqDist(str_para)\n",
    "print(Freq_Words.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995c8eda",
   "metadata": {},
   "source": [
    "3.Find the frequency of all words and also display the most and least frequent word.\n",
    "<p>Program Description: As part of preprocessing we find the frequency or the number of times a word occurs in the paragraph. Also, we find the least occuring word.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>First tokenize the paragraph using <i>word_tokenize()</i> from the NLTK library</li>\n",
    "<li> Using the <i>FreqDist()</i> we get the frequency distribution of the words in the paragraph. </li>\n",
    "<li>The <i>FreqDist()</i> function returns a tuple with word occuring frequently comming first.</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c6a6261",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized List:  ['Formula', 'One', '(', 'F1', ')', 'is', 'the', 'highest', 'class', 'of', 'worldwide', 'racing', 'for', 'open-wheel', 'single-seater', 'formula', 'racing', 'cars', 'sanctioned', 'by', 'the', 'Fédération', 'Internationale', 'de', \"l'Automobile\", '(', 'FIA', ')', '.', 'The', 'FIA', 'Formula', 'One', 'World', 'Championship', 'has', 'been', 'one', 'of', 'the', 'world', \"'s\", 'premier', 'forms', 'of', 'motorsport', 'since', 'its', 'inaugural', 'running', 'in', '1950', 'and', 'is', 'often', 'considered', 'to', 'be', 'the', 'pinnacle', 'of', 'motorsport', '.', 'The', 'word', 'formula', 'in', 'the', 'name', 'refers', 'to', 'the', 'set', 'of', 'rules', 'all', 'participant', 'cars', 'must', 'follow', '.', 'A', 'Formula', 'One', 'season', 'consists', 'of', 'a', 'series', 'of', 'races', ',', 'known', 'as', 'Grands', 'Prix', '.', 'Grands', 'Prix', 'take', 'place', 'in', 'multiple', 'countries', 'and', 'continents', 'on', 'either', 'purpose-built', 'circuits', 'or', 'closed', 'roadsz', '.']\n",
      "\n",
      "Frequency of words:  [('of', 7), ('the', 6), ('.', 5), ('Formula', 3), ('One', 3), ('in', 3), ('(', 2), (')', 2), ('is', 2), ('racing', 2), ('formula', 2), ('cars', 2), ('FIA', 2), ('The', 2), ('motorsport', 2), ('and', 2), ('to', 2), ('Grands', 2), ('Prix', 2), ('F1', 1)]\n",
      "\n",
      "Most frequent word is ' of ' with frequency:  7\n",
      "\n",
      "Least frequent words:  [('F1', 1)]\n"
     ]
    }
   ],
   "source": [
    "tokenised_str = word_tokenize(str_para)\n",
    "Freq_tokenwords = FreqDist(tokenised_str).most_common(20)\n",
    "print(\"Tokenized List: \",tokenised_str)\n",
    "print(\"\\nFrequency of words: \",Freq_tokenwords)\n",
    "\n",
    "#Most frequent and less frequent word\n",
    "print(\"\\nMost frequent word is '\", Freq_tokenwords[0][0],\"' with frequency: \", Freq_tokenwords[0][1])\n",
    "print(\"\\nLeast frequent words: \", [w for w in Freq_tokenwords if w[1]==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a013bd90",
   "metadata": {},
   "source": [
    "4.Find the longest word in the paragraph\n",
    "<p>Program Description: Our aim is to find the longest word that occurs in the paragraph.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>We use list comphrehension to return a tuple containing word indexes and their respective lengths.</li>\n",
    "<li> Using the <i>max()</i> fn we find the word with the maximum length. </li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07fe303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest word:  Internationale\n"
     ]
    }
   ],
   "source": [
    "word_lengths = [(tokenised_str.index(w),len(w)) for w in tokenised_str]\n",
    "longest_word = tokenised_str[max(word_lengths, key = lambda x:x[1])[0]]\n",
    "print(\"Longest word: \",longest_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020fdc0e",
   "metadata": {},
   "source": [
    "<h5>Question 3: Regular Expression\n",
    "Solve exercise 2.1 and 2.2 from Text book of Speech and Language Processing of Daniel Jurafsky and team</h5>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7deeb167",
   "metadata": {},
   "source": [
    "Write regular expressions for the following languages.\n",
    "1.the set of all alphabetic strings;\n",
    "<p>Program Description: Our aim is to check whether a given string has only alphabets or not.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: re(Regular Expression)</li>\n",
    "<li>We compare the test strings with the re pattern using <i>re.fullmatch()</i></li>\n",
    "</p>\n",
    "<p><u>Test Cases</u><br> \n",
    "<li>\"Hans\"-> True</li>\n",
    "<li>\"test123\"-> False</li>\n",
    "<li>\"lucky05\"-> False</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0303d23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hans -> True\n",
      "test123-> False\n",
      "ABC -> True\n",
      "lucky05-> False\n",
      "hi_there-> False\n",
      "123-> False\n",
      "hey!-> False\n"
     ]
    }
   ],
   "source": [
    "pattern = r'^[a-zA-Z]*$'\n",
    "test_strings = [\"Hans\", \"test123\", \"ABC\", \"lucky05\", \"hi_there\", \"123\", \"hey!\"]\n",
    "\n",
    "for s in test_strings:\n",
    "    if re.fullmatch(pattern, s):\n",
    "        print(f\"{s} -> True\")\n",
    "    else:\n",
    "        print(f\"{s }-> False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b6dd5f",
   "metadata": {},
   "source": [
    "2.The set of all lower case alphabetic strings ending in a b;\n",
    "<p>Program Description: Our aim is to check whether a given string is ending in b or not.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: re(Regular Expression)</li>\n",
    "<li>We compare the test strings with the re pattern using <i>re.fullmatch()</i></li>\n",
    "</p>\n",
    "<p><u>Test Cases</u><br> \n",
    "<li>\"lob\"-> True</li>\n",
    "<li>\"Job\"-> True</li>\n",
    "<li>\"Live\"-> False</li>\n",
    "<li>\"job123\"-> False</li>\n",
    "<li>\"lucky05\"-> False</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15e14fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job -> True\n",
      "Live -> False\n",
      "347 -> False\n",
      "job123 -> False\n",
      "lob -> True\n"
     ]
    }
   ],
   "source": [
    "pattern2  = r'[a-zA-z]*b'\n",
    "test_strings2 = [\"Job\",\"Live\", \"347\",\"job123\",\"lob\"]\n",
    "for s in test_strings2:\n",
    "    if re.fullmatch(pattern2, s):\n",
    "        print(f\"{s} -> True\")\n",
    "    else:\n",
    "        print(f\"{s} -> False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814a2838",
   "metadata": {},
   "source": [
    "3.The set of all strings from the alphabet a,b such that each a is immediately preceded by and immediately followed by a b\n",
    "<p>Program Description: Our aim is to check whether a string has the format: the alphabet a,b such that each a is immediately preceded by and immediately followed by a b.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: re(Regular Expression)</li>\n",
    "<li>We compare the test strings with the re pattern using <i>re.fullmatch()</i></li>\n",
    "</p>\n",
    "<p><u>Test Cases</u><br> \n",
    "<li>\"bbbbbabbbb\"-> True</li>\n",
    "<li>\"bbabbb\"-> True</li>\n",
    "<li>\"ab\"-> False</li>\n",
    "<li>\"abb\"-> False</li>\n",
    "<li>\"baba\"-> False</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "411a5582",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bbbbbabbbb -> True\n",
      "ab -> False\n",
      "baba -> False\n",
      "bbabbb -> True\n",
      "abb -> False\n"
     ]
    }
   ],
   "source": [
    "pattern3 = 'b*(bab)*b*'\n",
    "test_strings3 = [\"bbbbbabbbb\", \"ab\", \"baba\",\"bbabbb\",\"abb\"]\n",
    "for s in test_strings3:\n",
    "    if re.fullmatch(pattern3, s):\n",
    "        print(f\"{s} -> True\")\n",
    "    else:\n",
    "        print(f\"{s} -> False\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aa0baab",
   "metadata": {},
   "source": [
    "Write regular expressions for the following languages. By “word”, we mean\n",
    "an alphabetic string separated from other words by whitespace, any relevant\n",
    "punctuation, line breaks, and so forth.\n",
    "\n",
    "1.the set of all strings with two consecutive repeated words (e.g., “Hum-\n",
    "bert Humbert” and “the the” but not “the bug” or “the big bug”);\n",
    "<p>Program Description: Find an re pattern that will match words that appear consecutively in a sentence.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: re(Regular Expression)</li>\n",
    "<li>We use the <i>re.search()</i>  fn to search if the pattern exist in the sentence or not</li>\n",
    "</p>\n",
    "<p><u>Test Cases</u><br> \n",
    "<li>\"My grandma is the the mayor of Kerala.\"-> True</li>\n",
    "<li>\"Humbert Humbert speaks delusional stuff\"-> True</li>\n",
    "<li>\"There is a cat on top of the mat.\"-> False</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5382d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My grandma is the the mayor of Trivandrum.  -> True\n",
      "Humbert Humbert speaks delusional stuff.  -> True\n",
      "There is a cat on top of the mat. -> False\n"
     ]
    }
   ],
   "source": [
    "pattern4 = r'\\b(\\w+)\\b(?:[\\s,.!?;:-]+)\\b\\1\\b'\n",
    "\n",
    "test_sent = \"My grandma is the the mayor of Trivandrum.\"\n",
    "test_sent2 = \"Humbert Humbert speaks delusional stuff.\"\n",
    "test_sent3 = \"There is a cat on top of the mat.\"\n",
    "print(test_sent,\" ->\", True if re.search(pattern4, test_sent, re.IGNORECASE) else False)\n",
    "print(test_sent2,\" ->\", True if re.search(pattern4, test_sent2, re.IGNORECASE) else False)\n",
    "print(test_sent3 ,\"->\", True if re.search(pattern4, test_sent3, re.IGNORECASE) else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a2a024",
   "metadata": {},
   "source": [
    "2.All strings that start at the beginning of the line with an integer and that\n",
    "end at the end of the line with a word;\n",
    "<p>Program Description: Find an re pattern that will help us verify that whether the given sentence starts with a number and ends with a word.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: re(Regular Expression)</li>\n",
    "<li>Since we are trying to match a string with the pattern we use <i>re.search()</i>  fn to check if the sentence follows the pattern or not.</li>\n",
    "</p>\n",
    "<p><u>Test Cases</u><br> \n",
    "<li>\"123 is the number of my neighbor.\"-> True</li>\n",
    "<li>\"Divya has a haemoglobin level of 12.\"-> False</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94fb2707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123 is the number of my neighbor ->  True\n",
      "Divya has a haemoglobin level of 12 ->  False\n"
     ]
    }
   ],
   "source": [
    "test_sent1 = \"123 is the number of my neighbor\"\n",
    "test_sent2 = \"Divya has a haemoglobin level of 12\"\n",
    "match1 = re.search(r'^\\d+.*\\b[a-zA-Z]+\\b$', test_sent1)\n",
    "match2 = re.search(r'^\\d+.*\\b[a-zA-Z]+\\b$', test_sent2)\n",
    "print(test_sent1, \"-> \",True if match1 else False)\n",
    "print(test_sent2, \"-> \",True if match2 else False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56495dda",
   "metadata": {},
   "source": [
    "3.All strings that have both the word grotto and the word raven in them\n",
    "(but not, e.g., words like grottos that merely contain the word grotto);\n",
    "<p>Program Description: Find an re pattern that will help us verify whether the given sentence has both the words raven and grotto.</p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: re(Regular Expression)</li>\n",
    "<li>We use <i>re.search()</i>  fn to search if the words exist in the sentence or not</li>\n",
    "</p>\n",
    "<p><u>Test Cases</u><br> \n",
    "<li>\"The raven flew to the grotto\"-> True</li>\n",
    "<li>\"The raven flew into grottos\"-> False</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3dac2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raven flew to the grotto ->  True\n",
      "The raven flew into grottos ->  False\n"
     ]
    }
   ],
   "source": [
    "text1 = \"The raven flew to the grotto\"\n",
    "text2 = \"The raven flew into grottos\"\n",
    "if re.search(r'(?=.*\\bgrotto\\b)(?=.*\\braven\\b)', text1, re.IGNORECASE):\n",
    "    print(text1, \"-> \", True)\n",
    "else:    \n",
    "    print(text1, \"-> \", False)\n",
    "\n",
    "\n",
    "if re.search(r'(?=.*\\bgrotto\\b)(?=.*\\braven\\b)', text2, re.IGNORECASE):\n",
    "    print(text2, \"-> \", True)\n",
    "else:    \n",
    "    print(text2, \"-> \", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4346e690",
   "metadata": {},
   "source": [
    "4.Write a pattern that places the first word of an English sentence in a\n",
    "register. Deal with punctuation.\n",
    "<p>Program Description: The goal of the program is to extract the first word of an English sentence and store it in a register. It takes care to ignore leading punctuation and whitespace, such as quotation marks or spaces. </p>\n",
    "<p><u>Program Logic</u><br> \n",
    "<li>Libraries used: re(Regular Expression)</li>\n",
    "<li>The code uses a regular expression (re.match) to locate the first word that begins with a capital letter—as expected in grammatically correct English sentences.</li>\n",
    "<li>If a match is found, match.group(1) retrieves the first word (without quotes/punctuation).</li>\n",
    "</p>\n",
    "<p><u>Test Cases</u><br> \n",
    "<li>\"\"Hello there!\" he said.\"-> Hello</li>\n",
    "<li>\"Amazing!!! presentation Mr Akshay!!\"-> Amazing</li>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f3ae740",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Hello there!\" he said. , First word: Hello\n",
      "Amazing!!! presentation Mr Akshay!! , First word: Amazing\n"
     ]
    }
   ],
   "source": [
    "text1 = '\"Hello there!\" he said.'\n",
    "text2 = 'Amazing!!! presentation Mr Akshay!!'\n",
    "match1 = re.match(r'^[\\s\"\\']*([a-zA-Z][a-zA-Z]*)\\b', text1)\n",
    "if match1:\n",
    "    first_word = match1.group(1)\n",
    "    print(text1,\", First word:\", first_word)\n",
    "match2 = re.match(r'^[\\s\"\\']*([A-Z][a-zA-Z]*)\\b', text2)\n",
    "if match2:\n",
    "    first_word = match2.group(1)\n",
    "    print(text2,\", First word:\", first_word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb4fcf",
   "metadata": {},
   "source": [
    "<u>Comments</u>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9862b",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
